# ğŸš€ DuneNet Model API

Complete FastAPI server with Next.js dashboard integration featuring an interactive visual workflow system for your PyTorch perception model.

## âš¡ Quick Start

```bash
# 1. Install dependencies
pip install -r api_server/requirements.txt

# 2. Start API server
start_api.bat  # Windows
# or
./start_api.sh  # Linux/Mac

# 3. Start dashboard (in new terminal)
cd DuneNet
npm run dev

# 4. Open browser
# http://localhost:3000/dashboard
# Try the "Visual Pipeline" tab!
```

## ğŸ¯ What You Get

- âœ… **Visual Workflow System** - n8n-style interactive pipeline (NEW!)
- âœ… **Dynamic Parameter Editing** - Modify algorithm on the fly
- âœ… **What-If Analysis** - Predict impact before changes
- âœ… **Real-time Status Tracking** - Green/red/yellow node states
- âœ… **FastAPI Backend** - REST API for model inference
- âœ… **Next.js Dashboard** - Beautiful UI with multiple views
- âœ… **Image Upload** - Drag & drop interface
- âœ… **GPU Support** - Automatic GPU/CPU detection
- âœ… **Complete Documentation** - Guides for every level

## ğŸ“Š Features

### Visual Workflow System (NEW!)
- Interactive n8n-style pipeline visualization
- Real-time status tracking (green/red/yellow nodes)
- Dynamic parameter editing with live preview
- What-if analysis - predict impact before applying
- Visual debugging - identify failures instantly
- 7-stage perception pipeline visualization

### Backend (FastAPI)
- Health check endpoint
- Image upload and inference
- Model information endpoint
- CORS enabled
- Interactive API docs (Swagger)
- Error handling

### Frontend (Next.js)
- Visual Pipeline tab - Interactive workflow
- Model Inference tab - Simple predictions
- Training metrics visualization
- Per-class IoU analysis
- Model quality radar
- Experiment tracking
- Drag & drop image upload
- Real-time results

## ğŸ“ Project Structure

```
c:\spit\
â”œâ”€â”€ api_server/              # FastAPI backend
â”‚   â”œâ”€â”€ main.py             # API server
â”‚   â”œâ”€â”€ requirements.txt    # Dependencies
â”‚   â””â”€â”€ test_api.py        # Test script
â”œâ”€â”€ DuneNet/                # Next.js frontend
â”‚   â”œâ”€â”€ app/dashboard/
â”‚   â”‚   â””â”€â”€ page.js        # Dashboard with inference
â”‚   â””â”€â”€ components/
â”‚       â””â”€â”€ ModelInference.jsx  # Inference UI
â”œâ”€â”€ best_model.pth         # Your trained model
â”œâ”€â”€ inference.py           # Standalone script
â””â”€â”€ start_api.bat         # Startup script
```

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/` | GET | Health check |
| `/predict` | POST | Run inference |
| `/model/info` | GET | Model details |
| `/docs` | GET | API documentation |

## ğŸ“š Documentation

- **[INDEX.md](INDEX.md)** - Complete documentation index
- **[VISUAL_WORKFLOW_GUIDE.md](VISUAL_WORKFLOW_GUIDE.md)** - Visual pipeline guide (NEW!)
- **[QUICK_START.md](QUICK_START.md)** - Get started in 3 steps
- **[SETUP_GUIDE.md](SETUP_GUIDE.md)** - Detailed setup instructions
- **[VISUAL_GUIDE.md](VISUAL_GUIDE.md)** - Step-by-step walkthrough
- **[README_API.md](README_API.md)** - API documentation
- **[ARCHITECTURE.md](ARCHITECTURE.md)** - System architecture
- **[PROJECT_SUMMARY.md](PROJECT_SUMMARY.md)** - Project overview

## ğŸ§ª Testing

```bash
# Test API
cd api_server
python test_api.py

# Test with image
python test_api.py path/to/image.jpg
```

## ğŸ¨ Dashboard Preview

The dashboard now features:

### Visual Pipeline Tab (NEW!)
- Interactive workflow visualization
- 7 processing stages with real-time status
- Click nodes to modify parameters
- What-if analysis before applying changes
- Green (success) / Red (error) / Yellow (processing) states
- Animated data flow between nodes

### Model Inference Tab
- Image upload (drag & drop)
- Image preview
- One-click inference
- Results display (prediction + confidence)
- Device information (GPU/CPU)
- Error handling

## ğŸ”§ Configuration

### Change Image Size
Edit `api_server/main.py`:
```python
image = image.resize((224, 224))  # Change size
```

### Change API Port
Edit `api_server/main.py`:
```python
uvicorn.run(app, host="0.0.0.0", port=8000)  # Change port
```

## ğŸ› Troubleshooting

**API won't start?**
```bash
pip install -r api_server/requirements.txt
```

**Model not loading?**
- Verify `best_model.pth` exists in root directory

**Connection refused?**
- Ensure API is running on port 8000
- Check: `http://localhost:8000/`

**CORS errors?**
- Verify API server is running
- Check CORS settings in `api_server/main.py`

## ğŸ“ˆ Performance

- **Model Loading**: Once at startup
- **Inference Time**: < 1 second (GPU) / 1-3 seconds (CPU)
- **Image Processing**: Automatic resize to 224x224
- **GPU Support**: Automatic detection

## ğŸš€ Deployment

Ready for production? Check [ARCHITECTURE.md](ARCHITECTURE.md) for:
- Docker deployment
- Cloud platforms (AWS, GCP, Azure)
- Serverless options
- Security best practices

## ğŸ’¡ Tips

- Keep both terminals open (API + Dashboard)
- Check console logs for errors
- Use `/docs` endpoint for API testing
- Start with small images for testing
- Monitor GPU usage if available

## âœ… Verification Checklist

- [ ] Python dependencies installed
- [ ] API server starts without errors
- [ ] Model loads successfully
- [ ] Dashboard runs on port 3000
- [ ] Model Inference tab visible
- [ ] Can upload and process images
- [ ] Results display correctly

## ğŸ¯ Next Steps

1. Test with your images
2. Customize preprocessing
3. Add more features
4. Optimize performance
5. Deploy to production

## ğŸ“ Need Help?

1. Check the [documentation](INDEX.md)
2. Run the test script
3. Check console logs
4. Review error messages

## ğŸ‰ Success!

If you can:
- âœ“ Start both servers
- âœ“ Access the dashboard
- âœ“ Upload images
- âœ“ Get predictions

**You're all set! Happy inferencing! ğŸŠ**

---

**Documentation**: [INDEX.md](INDEX.md) | **Quick Start**: [QUICK_START.md](QUICK_START.md) | **API Docs**: [README_API.md](README_API.md)
